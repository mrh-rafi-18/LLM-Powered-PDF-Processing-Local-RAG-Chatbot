{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Required Libraries to Install**"
      ],
      "metadata": {
        "id": "vDiaT22rnp4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf huggingface_hub"
      ],
      "metadata": {
        "id": "YzgPn6Dz6bTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac59c25-4ffa-428b-f663-926d1844a235"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Provide Huggingface API Key Here**"
      ],
      "metadata": {
        "id": "1mP1O0owndwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"Paste token here\"\n"
      ],
      "metadata": {
        "id": "4Jnsab6H6bFj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PDF DATA EXTRACTION USING LLM**"
      ],
      "metadata": {
        "id": "NlAzf7sy0Klk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import base64\n",
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Upload PDF\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Convert PDF pages to base64 images\n",
        "def pdf_to_base64_pages(pdf_path, dpi=150, img_format=\"png\"):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    base64_pages = []\n",
        "\n",
        "    for page in doc:\n",
        "        pix = page.get_pixmap(dpi=dpi)\n",
        "        img_bytes = pix.tobytes(img_format)\n",
        "        img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
        "        base64_pages.append(f\"data:image/{img_format};base64,{img_b64}\")\n",
        "\n",
        "    return base64_pages\n",
        "\n",
        "pages_b64 = pdf_to_base64_pages(pdf_path)\n",
        "\n",
        "# Step 3: Initialize Hugging Face InferenceClient\n",
        "client = InferenceClient(\n",
        "    provider=\"novita\",\n",
        "    api_key=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        ")\n",
        "\n",
        "\n",
        "prompt=\"\"\"You are an intelligent image analysis assistant who can extract information from the images also those images that are embedded within the image. Your task is to extract information from images as accurately and completely as possible. You should detect text, tables, and embedded images, and provide concise descriptions for regular images. Always follow the output format strictly, even if some sections are empty.\n",
        "\n",
        "\n",
        "\n",
        "Analyze the provided image and extract information according to the following rules:\n",
        "\n",
        "\n",
        "\n",
        "###1.Textual Information:\n",
        "\n",
        "(In this section you will provide the textual information as it is in the picture)\n",
        "\n",
        "Extract all visible text exactly as it appears in the image.\n",
        "\n",
        "Preserve line breaks, punctuation, and order. if it is double columned provide in single column.\n",
        "\n",
        "\n",
        "\n",
        "###2.Tables:\n",
        "\n",
        "\n",
        "(In this section you will provide all tables also those tables that are in embedded images)\n",
        "\n",
        "Extract all tables in a structured format.\n",
        "\n",
        "Include tables that are embedded inside images or diagrams.\n",
        "\n",
        "If tables have titles, include them.(If it doesn't have any title provide one according to table information)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###3.Textual Information in Embedded Images:\n",
        "\n",
        "(In this section you will provide all the textual information that are in embedded images with numbering serially.)\n",
        "\n",
        "Detect any text present within images inside the main image (e.g., charts, signs, screenshots).\n",
        "\n",
        "Extract the text exactly as it appears.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###4.Images Short Description:\n",
        "\n",
        "(In this section you will provide the short descriptions of the regular images.)\n",
        "\n",
        "For any regular embedded images, provide a very short description (e.g., “Image 1: a bar chart(short description),” “Image 2: a landscape photo(short description)”).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Important Rules:\n",
        "\n",
        "Always output all four sections, even if some are blank.Just provide \"None\" there.\n",
        "\n",
        "Do not merge sections.\n",
        "\n",
        "Do not add extra explanations or commentary.\n",
        "\n",
        "Preserve the exact structure below:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: Send pages one by one to model\n",
        "for i, page_b64 in enumerate(pages_b64, start=1):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"Qwen/Qwen3-VL-235B-A22B-Instruct\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": page_b64}\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    print(f\"\\n--- Page {i} ---\\n\")\n",
        "    print(completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "BTb79Owp6bOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1163e12-44d0-48ab-ec6e-5d06c8d8e092"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f4c8b7a-8b95-47a0-99a0-549a6a178d72\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f4c8b7a-8b95-47a0-99a0-549a6a178d72\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test PDF.pdf to Test PDF.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Page 1 ---\n",
            "\n",
            "###1.Textual Information:\n",
            "Machine Learning: An Overview\n",
            "\n",
            "Introduction\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables systems to learn and improve from experience without being explicitly programmed. Unlike traditional programming, where rules are hard-coded, ML algorithms identify patterns in data and make predictions or decisions based on those patterns.\n",
            "\n",
            "Machine Learning has transformed various industries, including healthcare, finance, retail, and autonomous vehicles. The rapid increase in computational power, availability of big data, and advanced algorithms have fueled its growth.\n",
            "\n",
            "Types of Machine Learning\n",
            "\n",
            "Machine Learning is broadly classified into three categories:\n",
            "\n",
            "1. Supervised Learning\n",
            "In supervised learning, the algorithm is trained on a labeled dataset, meaning the input data comes with the correct output. The model learns to map inputs to outputs and can then predict outcomes for new data.\n",
            "Examples: Predicting house prices, email spam detection.\n",
            "\n",
            "2. Unsupervised Learning\n",
            "Unsupervised learning deals with unlabeled data. The algorithm tries to identify hidden patterns or structures within the data.\n",
            "Examples: Customer segmentation, anomaly detection, topic modeling.\n",
            "\n",
            "3. Reinforcement Learning\n",
            "Reinforcement learning trains an agent to make sequences of decisions by rewarding\n",
            "\n",
            "###2.Tables:\n",
            "None\n",
            "\n",
            "###3.Textual Information in Embedded Images:\n",
            "1. MACHINE LEARNING\n",
            "\n",
            "###4.Images Short Description:\n",
            "Image 1: a stylized illustration of a human head with circuitry and icons representing machine learning concepts.\n",
            "\n",
            "--- Page 2 ---\n",
            "\n",
            "###1.Textual Information:\n",
            "desired behavior and penalizing undesired actions.\n",
            "Examples: Game-playing AI, robotics navigation, autonomous driving.\n",
            "\n",
            "Key Steps in a Machine Learning Project\n",
            "\n",
            "Applications of Machine Learning\n",
            "Machine Learning has widespread applications:\n",
            "- Healthcare: Disease diagnosis, personalized treatment, drug discovery.\n",
            "- Finance: Fraud detection, credit scoring, algorithmic trading.\n",
            "- Retail & E-commerce: Recommendation systems, demand forecasting.\n",
            "- Autonomous Systems: Self-driving cars, drones, robotics.\n",
            "- Natural Language Processing: Chatbots, translation, sentiment analysis.\n",
            "\n",
            "###2.Tables:\n",
            "| Step               | Description                                                                 |\n",
            "|--------------------|-----------------------------------------------------------------------------|\n",
            "| Data Collection    | Gather relevant data from sources like sensors, databases, or web APIs.     |\n",
            "| Data Preprocessing | Clean, normalize, and transform raw data to make it suitable for training.  |\n",
            "| Feature Engineering| Select and create meaningful features that improve model performance.       |\n",
            "| Model Selection    | Choose an appropriate ML algorithm (e.g., linear regression, decision trees, neural networks). |\n",
            "| Training           | Fit the model to the training data to learn patterns.                       |\n",
            "| Evaluation         | Assess the model using metrics such as accuracy, precision, recall, and F1-score. |\n",
            "| Deployment         | Integrate the trained model into applications for real-world use.           |\n",
            "| Monitoring & Maintenance | Continuously monitor performance and update the model as new data becomes available. |\n",
            "\n",
            "###3.Textual Information in Embedded Images:\n",
            "None\n",
            "\n",
            "###4.Images Short Description:\n",
            "None\n",
            "\n",
            "--- Page 3 ---\n",
            "\n",
            "###1.Textual Information:\n",
            "Application Area\tUse Cases\tExample\n",
            "Healthcare\tDisease diagnosis, treatment planning\tPredicting cancer from medical images\n",
            "Finance\tFraud detection, credit scoring\tDetecting fraudulent transactions\n",
            "Retail & E-commerce\tRecommendation, demand forecasting\tSuggesting products to customers\n",
            "Autonomous Systems\tNavigation, robotics\tSelf-driving cars, delivery drones\n",
            "Natural Language Processing (NLP)\tChatbots, sentiment analysis\tCustomer support chatbots\n",
            "Marketing & Advertising\tCustomer segmentation, targeted ads\tPersonalized ad campaigns\n",
            "Manufacturing\tPredictive maintenance, quality control\tMachine failure prediction\n",
            "Cybersecurity\tThreat detection, anomaly detection\tMalware detection\n",
            "\n",
            "Challenges in Machine Learning\n",
            "\n",
            "Despite its potential, ML faces several challenges:\n",
            "\n",
            "•\tData Quality & Quantity: Poor or insufficient data can lead to inaccurate models.\n",
            "•\tOverfitting & Underfitting: Models may perform well on training data but fail on new data.\n",
            "•\tInterpretability: Complex models like deep neural networks can act as “black boxes.”\n",
            "•\tBias & Fairness: ML models can unintentionally learn biases present in training data.\n",
            "•\tComputational Resources: Training large models requires high processing power and memory.\n",
            "\n",
            "Conclusion\n",
            "\n",
            "Machine Learning is a powerful tool that enables computers to learn from data and make intelligent decisions. With the continued growth of data and computing, ML will increasingly impact industries and daily life. Successful implementation, however, requires careful attention to data quality, model selection, and ethical considerations.\n",
            "\n",
            "###2.Tables:\n",
            "| Application Area             | Use Cases                          | Example                        |\n",
            "|------------------------------|------------------------------------|--------------------------------|\n",
            "| Healthcare                   | Disease diagnosis, treatment planning | Predicting cancer from medical images |\n",
            "| Finance                      | Fraud detection, credit scoring    | Detecting fraudulent transactions |\n",
            "| Retail & E-commerce          | Recommendation, demand forecasting | Suggesting products to customers |\n",
            "| Autonomous Systems           | Navigation, robotics               | Self-driving cars, delivery drones |\n",
            "| Natural Language Processing (NLP) | Chatbots, sentiment analysis     | Customer support chatbots      |\n",
            "| Marketing & Advertising      | Customer segmentation, targeted ads | Personalized ad campaigns      |\n",
            "| Manufacturing                | Predictive maintenance, quality control | Machine failure prediction     |\n",
            "| Cybersecurity                | Threat detection, anomaly detection | Malware detection              |\n",
            "\n",
            "###3.Textual Information in Embedded Images:\n",
            "None\n",
            "\n",
            "###4.Images Short Description:\n",
            "None\n",
            "\n",
            "--- Page 4 ---\n",
            "\n",
            "###1.Textual Information:\n",
            "Summary\n",
            "Machine Learning (ML) is a branch of Artificial Intelligence that enables systems to learn from data and make predictions or decisions without explicit programming. It includes supervised learning (predicting outcomes from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through rewards and penalties). ML projects involve steps like data collection, preprocessing, feature engineering, model training, evaluation, deployment, and monitoring. Widely applied in healthcare, finance, retail, autonomous systems, and NLP, ML faces challenges such as data quality, overfitting, interpretability, bias, and computational demands. Despite these challenges, ML continues to transform industries by enabling intelligent, data-driven decision-making.\n",
            "\n",
            "###2.Tables:\n",
            "None\n",
            "\n",
            "###3.Textual Information in Embedded Images:\n",
            "None\n",
            "\n",
            "###4.Images Short Description:\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}